{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5ffu+gCjq3eLtuaWfEo/u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duruamobi/AAI2026/blob/B1/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "3NHi3ObMxKNH",
        "outputId": "96487e7f-fc51-4dfd-ffae-177150e94983"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'sample_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2335676982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ---- 1. Load data from CSV ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcsv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" CSV Data Loaded:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine  # Only for database example\n",
        "\n",
        "# ---- 1. Load data from CSV ----\n",
        "csv_data = pd.read_csv('sample_data.csv')\n",
        "print(\" CSV Data Loaded:\")\n",
        "print(csv_data.head())\n",
        "\n",
        "# ---- 2. Load data from Excel ----\n",
        "excel_data = pd.read_excel('sample_data.xlsx', engine='openpyxl')\n",
        "print(\"\\n Excel Data Loaded:\")\n",
        "print(excel_data.head())\n",
        "\n",
        "# ---- 3. Load data from a SQL database (Optional demo) ----\n",
        "# Example using SQLite for demonstration\n",
        "# Create a connection (replace with your DB URI)\n",
        "engine = create_engine('sqlite:///example.db')  # Assumes example.db exists\n",
        "# sql_data = pd.read_sql('SELECT * FROM your_table', engine)\n",
        "# print(\"\\n SQL Data Loaded:\")\n",
        "# print(sql_data.head())\n",
        "\n",
        "# ---- Basic Data Exploration ----\n",
        "print(\"\\n First 5 Rows:\")\n",
        "print(csv_data.head())\n",
        "\n",
        "print(\"\\n Last 5 Rows:\")\n",
        "print(csv_data.tail())\n",
        "\n",
        "print(\"\\n Info:\")\n",
        "csv_data.info()\n",
        "\n",
        "print(\"\\n Summary Statistics:\")\n",
        "print(csv_data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample raw dataset\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', None, 'Ethan'],\n",
        "    'Age': [23, np.nan, 22, 25, 24],\n",
        "    'Score': ['85', '90', None, '88', '92'],\n",
        "    'City': ['New York', 'Los Angeles', None, 'Chicago', 'Houston']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\" Raw Data:\")\n",
        "print(df)\n",
        "\n",
        "# ---- 1. Handling Missing Values ----\n",
        "\n",
        "# Drop rows with any missing values\n",
        "df_dropped = df.dropna()\n",
        "print(\"\\n Dropped Rows with Any Missing Values:\")\n",
        "print(df_dropped)\n",
        "\n",
        "# Fill missing values with a default value\n",
        "df_filled = df.fillna({'Name': 'Unknown', 'Age': df['Age'].mean(), 'Score': '0', 'City': 'Unknown'})\n",
        "print(\"\\n Filled Missing Values:\")\n",
        "print(df_filled)\n",
        "\n",
        "# ---- 2. Data Type Conversion ----\n",
        "\n",
        "# Convert 'Score' column from string to integer\n",
        "df_filled['Score'] = df_filled['Score'].astype(int)\n",
        "\n",
        "print(\"\\n After Converting 'Score' to Integer:\")\n",
        "print(df_filled.dtypes)\n",
        "\n",
        "# ---- 3. Data Filtering ----\n",
        "\n",
        "# Filter rows where Age is greater than 23\n",
        "filtered_df = df_filled[df_filled['Age'] > 23]\n",
        "print(\"\\n Filtered Rows (Age > 23):\")\n",
        "print(filtered_df)\n",
        "\n",
        "# ---- 4. Data Transformation ----\n",
        "\n",
        "# Add a new column with upper-case city names\n",
        "df_filled['City_Upper'] = df_filled['City'].str.upper()\n",
        "\n",
        "# Add a calculated column: Age * Score\n",
        "df_filled['Performance'] = df_filled['Age'] * df_filled['Score']\n",
        "\n",
        "print(\"\\n Transformed Data:\")\n",
        "print(df_filled)"
      ],
      "metadata": {
        "id": "cDTwxxt4y7km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Department': ['Sales', 'Sales', 'HR', 'HR', 'IT', 'IT', 'IT'],\n",
        "    'Employee': ['Alice', 'Bob', 'Charlie', 'Diana', 'Ethan', 'Fiona', 'George'],\n",
        "    'Salary': [60000, 65000, 58000, 62000, 70000, 72000, 71000],\n",
        "    'Bonus': [5000, 6000, 4000, 4500, 5500, 6000, 5800]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\" Original Data:\")\n",
        "print(df)\n",
        "\n",
        "# ---- 1. Grouping and Aggregation ----\n",
        "\n",
        "# Group by Department and calculate mean Salary and Bonus\n",
        "grouped = df.groupby('Department')[['Salary', 'Bonus']].mean()\n",
        "\n",
        "print(\"\\n Average Salary and Bonus by Department:\")\n",
        "print(grouped)\n",
        "\n",
        "# You can also use multiple aggregation functions\n",
        "grouped_multi = df.groupby('Department').agg({\n",
        "    'Salary': ['mean', 'max'],\n",
        "    'Bonus': 'sum'\n",
        "})\n",
        "\n",
        "print(\"\\n Grouped with Multiple Aggregations:\")\n",
        "print(grouped_multi)\n",
        "\n",
        "# ---- 2. Pivot Tables ----\n",
        "\n",
        "# Create a pivot table to show average Salary by Department\n",
        "pivot = pd.pivot_table(df, values='Salary', index='Department', aggfunc='mean')\n",
        "\n",
        "print(\"\\n Pivot Table - Average Salary by Department:\")\n",
        "print(pivot)\n",
        "\n",
        "# Pivot Table with multiple values and aggregation\n",
        "pivot_multi = pd.pivot_table(df, values=['Salary', 'Bonus'], index='Department', aggfunc='sum')\n",
        "\n",
        "print(\"\\n Pivot Table - Total Salary and Bonus by Department:\")\n",
        "print(pivot_multi)"
      ],
      "metadata": {
        "id": "eUyqA7hzy-ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Department': ['Sales', 'Sales', 'HR', 'HR', 'IT', 'IT', 'IT'],\n",
        "    'Employee': ['Alice', 'Bob', 'Charlie', 'Diana', 'Ethan', 'Fiona', 'George'],\n",
        "    'Salary': [60000, 65000, 58000, 62000, 70000, 72000, 71000],\n",
        "    'Bonus': [5000, 6000, 4000, 4500, 5500, 6000, 5800]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\" Original Data:\")\n",
        "print(df)\n",
        "\n",
        "# ---- 1. Grouping and Aggregation ----\n",
        "\n",
        "# Group by Department and calculate mean Salary and Bonus\n",
        "grouped = df.groupby('Department')[['Salary', 'Bonus']].mean()\n",
        "\n",
        "print(\"\\n Average Salary and Bonus by Department:\")\n",
        "print(grouped)\n",
        "\n",
        "# You can also use multiple aggregation functions\n",
        "grouped_multi = df.groupby('Department').agg({\n",
        "    'Salary': ['mean', 'max'],\n",
        "    'Bonus': 'sum'\n",
        "})\n",
        "\n",
        "print(\"\\n Grouped with Multiple Aggregations:\")\n",
        "print(grouped_multi)\n",
        "\n",
        "# ---- 2. Pivot Tables ----\n",
        "\n",
        "# Create a pivot table to show average Salary by Department\n",
        "pivot = pd.pivot_table(df, values='Salary', index='Department', aggfunc='mean')\n",
        "\n",
        "print(\"\\n Pivot Table - Average Salary by Department:\")\n",
        "print(pivot)\n",
        "\n",
        "# Pivot Table with multiple values and aggregation\n",
        "pivot_multi = pd.pivot_table(df, values=['Salary', 'Bonus'], index='Department', aggfunc='sum')\n",
        "\n",
        "print(\"\\n Pivot Table - Total Salary and Bonus by Department:\")\n",
        "print(pivot_multi)"
      ],
      "metadata": {
        "id": "VUEfqNt8zDum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ---- Sample DataFrames ----\n",
        "\n",
        "# First DataFrame: Employees\n",
        "df_employees = pd.DataFrame({\n",
        "    'EmployeeID': [1, 2, 3, 4],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
        "    'DepartmentID': [101, 102, 101, 103]\n",
        "})\n",
        "\n",
        "# Second DataFrame: Departments\n",
        "df_departments = pd.DataFrame({\n",
        "    'DepartmentID': [101, 102, 104],\n",
        "    'DepartmentName': ['Sales', 'HR', 'IT']\n",
        "})\n",
        "\n",
        "print(\" Employees DataFrame:\")\n",
        "print(df_employees)\n",
        "\n",
        "print(\"\\n Departments DataFrame:\")\n",
        "print(df_departments)\n",
        "\n",
        "# ---- 1. INNER JOIN (default) ----\n",
        "inner_join = pd.merge(df_employees, df_departments, on='DepartmentID', how='inner')\n",
        "print(\"\\n INNER JOIN (only matching rows):\")\n",
        "print(inner_join)\n",
        "\n",
        "# ---- 2. LEFT JOIN ----\n",
        "left_join = pd.merge(df_employees, df_departments, on='DepartmentID', how='left')\n",
        "print(\"\\n LEFT JOIN (all employees, with department info if available):\")\n",
        "print(left_join)\n",
        "\n",
        "# ---- 3. RIGHT JOIN ----\n",
        "right_join = pd.merge(df_employees, df_departments, on='DepartmentID', how='right')\n",
        "print(\"\\n RIGHT JOIN (all departments, with employee info if available):\")\n",
        "print(right_join)\n",
        "\n",
        "# ---- 4. OUTER JOIN ----\n",
        "outer_join = pd.merge(df_employees, df_departments, on='DepartmentID', how='outer')\n",
        "print(\"\\n OUTER JOIN (all rows from both, matched when possible):\")\n",
        "print(outer_join)"
      ],
      "metadata": {
        "id": "CutHgCA4zVvv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}